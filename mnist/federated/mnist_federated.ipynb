{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mnist_federated.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zvBXg9bzQuId"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZrGitA_KnRO0",
        "colab": {}
      },
      "source": [
        "!pip install --quiet --upgrade tensorflow_federated\n",
        "!pip install nest_asyncio\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8BKyHkMxKHfV",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "tff.federated_computation(lambda: 'Hello, World!')()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NayDhCX6SjwE",
        "colab": {}
      },
      "source": [
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EsvSXGEMgd9G",
        "colab": {}
      },
      "source": [
        "example_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[0])\n",
        "\n",
        "it = iter(example_dataset)\n",
        "\n",
        "for x in range(5):\n",
        "    example_element = next(it)\n",
        "\n",
        "example_element['label'].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TYrLZnWQzTO",
        "colab_type": "text"
      },
      "source": [
        "#modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cyG_BMraSuu_",
        "colab": {}
      },
      "source": [
        "NUM_CLIENTS = 5\n",
        "NUM_EPOCHS = 25\n",
        "BATCH_SIZE = 50\n",
        "SHUFFLE_BUFFER = 100\n",
        "PREFETCH_BUFFER=10\n",
        "NUM_CLASS = 10\n",
        "input_shape = (28, 28,1)\n",
        "\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "    \"\"\"Flatten a batch `image` and return the features as an `OrderedDict`.\"\"\"\n",
        "   \n",
        "    element['pixels'] = tf.expand_dims(element['pixels'], 3)\n",
        "\n",
        "    return collections.OrderedDict(\n",
        "        x = element['pixels'],\n",
        "        y = element['label'])\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_PHMvHAI9xVc",
        "colab": {}
      },
      "source": [
        "preprocessed_example_dataset = preprocess(example_dataset)\n",
        "\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),next(iter(preprocessed_example_dataset)))\n",
        "\n",
        "print(sample_batch['x'].shape)\n",
        "\n",
        "def make_federated_data(client_data, client_ids):\n",
        "  return [\n",
        "      preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "      for x in client_ids\n",
        "  ]\n",
        "\n",
        "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
        "\n",
        "\n",
        "federated_train_data = make_federated_data(emnist_train, sample_clients)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhvs6cyM3Scz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_keras_model():\n",
        "    return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Input(shape=input_shape),\n",
        "      tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
        "      tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      tf.keras.layers.Dropout(0.25),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(NUM_CLASS, activation='softmax'),\n",
        "    ])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q3ynrxd53HzY",
        "colab": {}
      },
      "source": [
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=preprocessed_example_dataset.element_spec,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs4Qepn-wxNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n",
        "\n",
        "state = iterative_process.initialize()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xU55J83jlkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import attr\n",
        "@attr.s(eq=False, frozen=True)\n",
        "class ServerState(object):\n",
        "  \"\"\"Structure for state on the server.\n",
        "  Fields:\n",
        "  -   `model`: A dictionary of model's trainable variables.\n",
        "  -   `optimizer_state`: the list of variables of the optimizer.\n",
        "  \"\"\"\n",
        "  model = attr.ib()\n",
        "  optimizer_state = attr.ib()\n",
        "\n",
        "  @classmethod\n",
        "  def from_tff_result(cls, anon_tuple):\n",
        "    return cls(\n",
        "        model=tff.learning.framework.ModelWeights.from_tff_result(anon_tuple.model),\n",
        "        optimizer_state=list(anon_tuple.optimizer_state))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myDWatMlT4wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#research folder contains the research files downloaded from Tensorflow Github page.\n",
        "!cd './research'"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_6-Jkx-Afff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import checkpoint_manager"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmIxeSuCD8f0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcGOlCuWER2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf './model_emnist_ff.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhC2BcwxAhGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir './model_emnist_ff.h5'"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qrJkQuCRJP9C",
        "colab": {}
      },
      "source": [
        "ckpt_manager = checkpoint_manager.FileCheckpointManager(\"./model_emnist_ff.h5\")\n",
        "\n",
        "\n",
        "import time\n",
        "first = time.time()\n",
        "print(\"first since epoch =\", first)\t\n",
        "\n",
        "NUM_ROUNDS = 101\n",
        "SIM_METRICS = [NUM_ROUNDS]\n",
        "\n",
        "\n",
        "USERS_PER_ROUND = NUM_CLIENTS\n",
        "\n",
        "for round_num in range(1, NUM_ROUNDS):\n",
        "\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print('round {:2d}, metrics={}'.format(round_num, metrics))\n",
        "   \n",
        "ckpt_manager.save_checkpoint(state, round_num=NUM_ROUNDS)\n",
        "seconds = time.time()\n",
        "print(\"Time diff =\", seconds - first)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLN7QLUNkqO",
        "colab_type": "text"
      },
      "source": [
        "#Mode Restore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f4GBCk7kvy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "restored_state = ckpt_manager.load_latest_checkpoint(state)\n",
        "\n",
        "model_last = create_keras_model()\n",
        "restored_state[0].model.assign_weights_to(model_last)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QttfmjuOpSQ",
        "colab_type": "text"
      },
      "source": [
        "#Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn1vZe5TNmWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_iterable(i):\n",
        "    return sum(1 for e in i)\n",
        "\n",
        "all_clients = 3383\n",
        "all_train_counts = []\n",
        "\n",
        "for client_id in range(all_clients):\n",
        "    example_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[client_id])\n",
        "    it = iter(example_dataset)\n",
        "    all_train_counts.append([])\n",
        "    c = count_iterable(it)\n",
        "    all_train_counts[client_id].append(c)\n",
        "\n",
        "#all_train_counts\n",
        "\n",
        "all_test_counts = []\n",
        "for client_id in range(all_clients):\n",
        "    example_dataset = emnist_test.create_tf_dataset_for_client(emnist_test.client_ids[client_id])\n",
        "    it = iter(example_dataset)\n",
        "    all_test_counts.append([])\n",
        "    c = count_iterable(it)\n",
        "    all_test_counts[client_id].append(c)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b6MeS8gXhrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLIENT_MAX = 3383\n",
        "\n",
        "def calculate_metric(model, client_num):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    per_client_total = 0\n",
        "    per_client_correct = 0\n",
        "    all_accuracy = []\n",
        "\n",
        "    for client_id in range(client_num):\n",
        "        all_accuracy.append([])\n",
        "        example_dataset = emnist_test.create_tf_dataset_for_client(emnist_test.client_ids[client_id])\n",
        "        #example_dataset = federated_test_data[client_id]\n",
        "        it = iter(example_dataset)\n",
        "        for img in range(all_test_counts[client_id][0]-1):\n",
        "            test_example_element = next(it)\n",
        "            actual_label = test_example_element['label'].numpy()\n",
        "            test_image = tf.reshape(test_example_element['pixels'].numpy(), [-1, 28, 28, 1])\n",
        "            predicted_label = model.predict_classes(test_image, batch_size=1)\n",
        "\n",
        "            per_client_total += 1\n",
        "            if(predicted_label[0] == actual_label):\n",
        "                per_client_correct += 1\n",
        "\n",
        "        all_accuracy[client_id].append(per_client_correct/per_client_total*100)\n",
        "        total += per_client_total\n",
        "        correct += per_client_correct\n",
        "        per_client_total = 0\n",
        "        per_client_correct = 0\n",
        "\n",
        "\n",
        "    return np.average(all_accuracy)\n",
        "\n",
        "\n",
        "model_accuracy = calculate_metric(model_last, CLIENT_MAX)\n",
        "print(model_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}